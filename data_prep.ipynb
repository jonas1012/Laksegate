{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c66e505",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "Preparation of multiple datasets\n",
    "## Full dataset\n",
    "\n",
    "The full dataset is only daily data, and is aggreagting data where multiple time of the day exists by the mean. \n",
    "\n",
    "Importing the notebooks for preparing the data. The data preparation should combine different csv files into a single combined csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2bf4f135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Directory containing the CSV files\n",
    "csv_directory_NO2 = './Air Quality dataset/NO2'  # Update this path to your folder containing CSV files\n",
    "csv_directory_NOx = './Air Quality dataset/NOx'  # Update this path to your folder containing CSV files\n",
    "output_file = './combined_data_full_wide.csv'  # Output file path\n",
    "\n",
    "# Initialize an empty DataFrame for combining data\n",
    "combined_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2f913b",
   "metadata": {},
   "source": [
    "The following code should create a date variable, that stretches from the earliest recorded date to the latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf6d475a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame with Date Range:\n",
      "        Date\n",
      "0 2005-01-01\n",
      "1 2005-01-02\n",
      "2 2005-01-03\n",
      "3 2005-01-04\n",
      "4 2005-01-05\n",
      "           Date\n",
      "6934 2023-12-27\n",
      "6935 2023-12-28\n",
      "6936 2023-12-29\n",
      "6937 2023-12-30\n",
      "6938 2023-12-31\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List to store all dates\n",
    "all_dates = []\n",
    "\n",
    "# Iterate through all CSV files in both directories\n",
    "for file in os.listdir(csv_directory_NO2):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join(csv_directory_NO2, file)\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "        if 'DatoMaerke' in df.columns:\n",
    "            all_dates.extend(pd.to_datetime(df['DatoMaerke']).tolist())\n",
    "for file in os.listdir(csv_directory_NOx):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join(csv_directory_NOx, file)\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "        if 'DatoMaerke' in df.columns:\n",
    "            all_dates.extend(pd.to_datetime(df['DatoMaerke']).tolist())\n",
    "\n",
    "# Create a date range from the earliest to the latest date\n",
    "if all_dates:\n",
    "    min_date = min(all_dates)\n",
    "    max_date = max(all_dates)\n",
    "    date_range = pd.date_range(start=min_date, end=max_date)\n",
    "\n",
    "    # Add the date range to the combined_df\n",
    "    combined_df['Date'] = date_range\n",
    "\n",
    "# Print the first few rows of the combined DataFrame\n",
    "print(\"Combined DataFrame with Date Range:\")\n",
    "print(combined_df.head())\n",
    "print(combined_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc58a00d",
   "metadata": {},
   "source": [
    "Now, the different NO2 values should be added. The NO2 values are stored in the column called 'NO2 ppb', and each new column should have the name of the file that it was extracted from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0156b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Combined DataFrame with NO2 Values:\n",
      "        Date  NO2_HCAB  NO2_JAGT  NO2_HCØ  NO2_HVID\n",
      "0 2005-01-01       NaN       NaN      NaN       NaN\n",
      "1 2005-01-02       NaN       NaN      NaN       NaN\n",
      "2 2005-01-03       NaN       NaN      NaN       NaN\n",
      "3 2005-01-04       NaN       NaN      NaN       NaN\n",
      "4 2005-01-05       NaN       NaN      NaN       NaN\n",
      "           Date   NO2_HCAB  NO2_JAGT   NO2_HCØ  NO2_HVID\n",
      "6934 2023-12-27  11.644610  8.385413  3.815012  6.156475\n",
      "6935 2023-12-28   8.119274  5.506321  1.871165  2.485123\n",
      "6936 2023-12-29   6.897775  4.161797  0.849568  1.481953\n",
      "6937 2023-12-30   9.153935  5.501731  1.626224  2.064372\n",
      "6938 2023-12-31   6.586321  6.814672  4.236740  3.916140\n"
     ]
    }
   ],
   "source": [
    "# Iterate through all CSV files in the directory\n",
    "for file in os.listdir(csv_directory_NO2):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join(csv_directory_NO2, file)\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Transform the 'DatoMaerke' into a column of dates and a column of times\n",
    "        if 'DatoMaerke' in df.columns:\n",
    "            df['Date'] = pd.to_datetime(df['DatoMaerke']).dt.date\n",
    "            df['Time'] = pd.to_datetime(df['DatoMaerke']).dt.time\n",
    "            df.drop(columns=['DatoMaerke'], inplace=True)\n",
    "        # Drop the time column if it exists\n",
    "        if 'Time' in df.columns:\n",
    "            df.drop(columns=['Time'], inplace=True)\n",
    "        # Group the data by date and calculate the mean NO2 values\n",
    "        df = df.groupby('Date').mean()\n",
    "\n",
    "        # Reindex to match the combined_df date range\n",
    "        df = df.reindex(date_range)\n",
    "        # Add the NO2 values as a new column in combined_df\n",
    "        column_name = os.path.splitext(file)[0]  # Use the file name (without extension) as the column name\n",
    "        combined_df[column_name] = df['NO2 ppb'].values\n",
    "\n",
    "# Rename the columns to 'NO2_HCAB', 'NO2_JAGT', 'NO2_HCØ' and 'NO2_HVID'\n",
    "combined_df = combined_df.rename(columns={combined_df.columns[1]: 'NO2_HCAB',\n",
    "                       combined_df.columns[2]: 'NO2_JAGT',\n",
    "                       combined_df.columns[3]: 'NO2_HCØ',\n",
    "                       combined_df.columns[4]: 'NO2_HVID'})\n",
    "\n",
    "# Print the first few rows of the updated combined DataFrame\n",
    "print(\"Updated Combined DataFrame with NO2 Values:\")\n",
    "print(combined_df.head())\n",
    "print(combined_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db87f1a2",
   "metadata": {},
   "source": [
    "The NOx should also be added in the same way as the NO2 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf5afd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Combined DataFrame with NOx Values:\n",
      "        Date  NO2_HCAB  NO2_JAGT  NO2_HCØ  NO2_HVID   NOx_HCAB   NOx_JAGT  \\\n",
      "0 2005-01-01       NaN       NaN      NaN       NaN  43.682987  38.077831   \n",
      "1 2005-01-02       NaN       NaN      NaN       NaN  16.190796  12.225522   \n",
      "2 2005-01-03       NaN       NaN      NaN       NaN  34.915861  15.252096   \n",
      "3 2005-01-04       NaN       NaN      NaN       NaN  32.540399  18.183066   \n",
      "4 2005-01-05       NaN       NaN      NaN       NaN  55.714600  33.479079   \n",
      "\n",
      "     NOx_HCØ  NOx_HVID  \n",
      "0  10.268396       NaN  \n",
      "1   5.092584       NaN  \n",
      "2   8.584316       NaN  \n",
      "3   8.705654       NaN  \n",
      "4  12.964224       NaN  \n",
      "           Date   NO2_HCAB  NO2_JAGT   NO2_HCØ  NO2_HVID   NOx_HCAB  \\\n",
      "6934 2023-12-27  11.644610  8.385413  3.815012  6.156475  21.084549   \n",
      "6935 2023-12-28   8.119274  5.506321  1.871165  2.485123  12.921235   \n",
      "6936 2023-12-29   6.897775  4.161797  0.849568  1.481953  11.556676   \n",
      "6937 2023-12-30   9.153935  5.501731  1.626224  2.064372  16.678878   \n",
      "6938 2023-12-31   6.586321  6.814672  4.236740  3.916140  10.198280   \n",
      "\n",
      "       NOx_JAGT   NOx_HCØ  NOx_HVID  \n",
      "6934  13.422952  3.983214  7.862207  \n",
      "6935   8.633315  1.907765  2.526577  \n",
      "6936   6.345956  0.863469  1.543493  \n",
      "6937   8.388270  1.700224  2.251147  \n",
      "6938  10.603858  4.510658  4.223581  \n"
     ]
    }
   ],
   "source": [
    "csv_directory_NOx = './Air Quality dataset/NOx' \n",
    "\n",
    "# Iterate through all CSV files in the directory\n",
    "for file in os.listdir(csv_directory_NOx):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join(csv_directory_NOx, file)\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Transform the 'DatoMaerke' into a column of dates and a column of times\n",
    "        if 'DatoMaerke' in df.columns:\n",
    "            df['Date'] = pd.to_datetime(df['DatoMaerke']).dt.date\n",
    "            df['Time'] = pd.to_datetime(df['DatoMaerke']).dt.time\n",
    "            df.drop(columns=['DatoMaerke'], inplace=True)\n",
    "        # Drop the time column if it exists\n",
    "        if 'Time' in df.columns:\n",
    "            df.drop(columns=['Time'], inplace=True)\n",
    "        # Group the data by date and calculate the mean NO2 values\n",
    "        df = df.groupby('Date').mean()\n",
    "\n",
    "        # Reindex to match the combined_df date range\n",
    "        df = df.reindex(date_range)\n",
    "        # Add the NO2 values as a new column in combined_df\n",
    "        column_name = os.path.splitext(file)[0]  # Use the file name (without extension) as the column name\n",
    "        combined_df[column_name] = df['NOx ppb'].values\n",
    "\n",
    "# Rename the columns appropriately for NOx data\n",
    "combined_df = combined_df.rename(columns={combined_df.columns[5]: 'NOx_HCAB',\n",
    "                       combined_df.columns[6]: 'NOx_JAGT',\n",
    "                       combined_df.columns[7]: 'NOx_HCØ',\n",
    "                       combined_df.columns[8]: 'NOx_HVID'})\n",
    "\n",
    "# Print the first few rows of the updated combined DataFrame\n",
    "print(\"Updated Combined DataFrame with NOx Values:\")\n",
    "print(combined_df.head())\n",
    "print(combined_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb36022e",
   "metadata": {},
   "source": [
    "### Adding a weekday column in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "799b85e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame with Weekday Column:\n",
      "        Date    Weekday  NO2_HCAB  NO2_JAGT  NO2_HCØ  NO2_HVID   NOx_HCAB  \\\n",
      "0 2005-01-01   Saturday       NaN       NaN      NaN       NaN  43.682987   \n",
      "1 2005-01-02     Sunday       NaN       NaN      NaN       NaN  16.190796   \n",
      "2 2005-01-03     Monday       NaN       NaN      NaN       NaN  34.915861   \n",
      "3 2005-01-04    Tuesday       NaN       NaN      NaN       NaN  32.540399   \n",
      "4 2005-01-05  Wednesday       NaN       NaN      NaN       NaN  55.714600   \n",
      "\n",
      "    NOx_JAGT    NOx_HCØ  NOx_HVID  \n",
      "0  38.077831  10.268396       NaN  \n",
      "1  12.225522   5.092584       NaN  \n",
      "2  15.252096   8.584316       NaN  \n",
      "3  18.183066   8.705654       NaN  \n",
      "4  33.479079  12.964224       NaN  \n"
     ]
    }
   ],
   "source": [
    "# Add a new column for the weekday corresponding to the 'Date' column\n",
    "combined_df['Weekday'] = combined_df['Date'].dt.day_name()\n",
    "\n",
    "# Reorder columns to make 'Weekday' the second column\n",
    "columns = list(combined_df.columns)\n",
    "columns.insert(1, columns.pop(columns.index('Weekday')))\n",
    "combined_df = combined_df[columns]\n",
    "\n",
    "# Print the first few rows to verify the new column\n",
    "print(\"Combined DataFrame with Weekday Column:\")\n",
    "print(combined_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a94df56",
   "metadata": {},
   "source": [
    "### Saving the data\n",
    "Now, the new data should be saved as a new csv-file called combined_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b79b304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to ./combined_data_full_wide.csv\n"
     ]
    }
   ],
   "source": [
    "combined_df.to_csv(output_file, index=False)\n",
    "print(f\"Data has been saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9124d73",
   "metadata": {},
   "source": [
    "## Hvidover dataset (hourly)\n",
    "The below code is hourly data, and is imported in the same fashion as before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eec98148",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Combined DataFrame with NO2 and NOx Values for 2020-2023:\n",
      "            DatoMaerke    Weekday        Date      Time   NO2_ppb   NOx_ppb\n",
      "0  2020-01-01 00:00:00  Wednesday  2020-01-01  00:00:00  8.287385  9.406047\n",
      "1  2020-01-01 01:00:00  Wednesday  2020-01-01  01:00:00  5.106675  5.388229\n",
      "2  2020-01-01 02:00:00  Wednesday  2020-01-01  02:00:00  4.295781  4.188985\n",
      "3  2020-01-01 03:00:00  Wednesday  2020-01-01  03:00:00  2.649493  2.579914\n",
      "4  2020-01-01 04:00:00  Wednesday  2020-01-01  04:00:00  4.290077  3.901728\n",
      "                DatoMaerke Weekday        Date      Time   NO2_ppb   NOx_ppb\n",
      "35059  2023-12-31 19:00:00  Sunday  2023-12-31  19:00:00  2.432005  2.872579\n",
      "35060  2023-12-31 20:00:00  Sunday  2023-12-31  20:00:00  2.298992  2.836902\n",
      "35061  2023-12-31 21:00:00  Sunday  2023-12-31  21:00:00  2.288536  2.677880\n",
      "35062  2023-12-31 22:00:00  Sunday  2023-12-31  22:00:00  2.320657  2.407748\n",
      "35063  2023-12-31 23:00:00  Sunday  2023-12-31  23:00:00  3.197052  3.335372\n"
     ]
    }
   ],
   "source": [
    "# Process the NO2 file\n",
    "file_no2 = 'NO2_773_HVID_2020-2023.csv'\n",
    "file_path_no2 = os.path.join(csv_directory_NO2, file_no2)\n",
    "\n",
    "# Initialize an empty DataFrame for combining data\n",
    "combined_df_hourly = pd.DataFrame()\n",
    "\n",
    "if os.path.exists(file_path_no2):\n",
    "    df_hvid = pd.read_csv(file_path_no2)\n",
    "\n",
    "    # Adding a weekday column\n",
    "    df_hvid['Weekday'] = pd.to_datetime(df_hvid['DatoMaerke']).dt.day_name()\n",
    "\n",
    "    # Retain 'DatoMaerke' and create 'Date' and 'Time' columns\n",
    "    if 'DatoMaerke' in df_hvid.columns:\n",
    "        df_hvid['Date'] = pd.to_datetime(df_hvid['DatoMaerke']).dt.date\n",
    "        df_hvid['Time'] = pd.to_datetime(df_hvid['DatoMaerke']).dt.time\n",
    "\n",
    "    combined_df_hourly = df_hvid.copy()\n",
    "\n",
    "    # Reorganize the 'NO2 ppb' column to be the last column and rename it to NO2_ppb\n",
    "    if 'NO2 ppb' in combined_df_hourly.columns:\n",
    "        combined_df_hourly.rename(columns={'NO2 ppb': 'NO2_ppb'}, inplace=True)\n",
    "        # Move the 'NO2_ppb' column to the end\n",
    "        cols = list(combined_df_hourly.columns)\n",
    "        cols.append(cols.pop(cols.index('NO2_ppb')))\n",
    "        combined_df_hourly = combined_df_hourly[cols]\n",
    "\n",
    "# Process the NOx file\n",
    "file_nox = 'NOx_773_HVID_2020-2023.csv'\n",
    "file_path_nox = os.path.join(csv_directory_NOx, file_nox)\n",
    "\n",
    "if os.path.exists(file_path_nox):\n",
    "    df_nox = pd.read_csv(file_path_nox)\n",
    "    \n",
    "    # Retain 'DatoMaerke' and create 'Date' and 'Time' columns\n",
    "    if 'DatoMaerke' in df_nox.columns:\n",
    "        df_nox['Date'] = pd.to_datetime(df_nox['DatoMaerke']).dt.date\n",
    "        df_nox['Time'] = pd.to_datetime(df_nox['DatoMaerke']).dt.time\n",
    "\n",
    "    # Add the NOx values as a new column in combined_df\n",
    "    combined_df_hourly['NOx_ppb'] = df_nox['NOx ppb'].values\n",
    "\n",
    "\n",
    "\n",
    "# Print the first few rows of the updated combined DataFrame\n",
    "print(\"Updated Combined DataFrame with NO2 and NOx Values for 2020-2023:\")\n",
    "print(combined_df_hourly.head())\n",
    "print(combined_df_hourly.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dca5ad",
   "metadata": {},
   "source": [
    "Saving the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f7ac7487",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to ./hourly_data_full.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the data as a CSV file\n",
    "output_file = './hourly_data_full.csv'  # Output file path\n",
    "combined_df_hourly.to_csv(output_file, index=False)\n",
    "print(f\"Data has been saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
